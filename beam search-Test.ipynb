{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本次研讨课内容:\n",
    "   问答摘要内容讲解:\n",
    "    1. beam search 讲解.\n",
    "    2. seq2seq baseline 编写\\训练\\测试.\n",
    "    3. 提交你的第一版成绩.\n",
    "    4. 预测结果分析,模型提升改进点讨论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "                print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "config_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. nvidia驱动   nvidia-smi\n",
    "2. CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 休息10分钟! 9:10分见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "去除标点符号  200\n",
    "不去除  500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch size 32\n",
    "max_x_len 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtx 2080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10轮/分钟  5轮 25分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-blog.csdn.net/20180414103300419)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码是seq2seq模型的常见问题，常用方法有贪心搜索`（Greedy Search）`集束搜索`（Beam Search）`。\n",
    "\n",
    "Decoder根据Encoder的中间语义编码向量c和`<s>`标签得到第一个输出的概率分布`[0.1,0.1,0.3,0.4,0.1]`，选择概率最大的`0.4`，即`moi`。\n",
    "\n",
    "根据隐向量h1h1和moi得到第二个输出的概率分布`[0.1,0.1,0.1,0.1,0.6][0.1,0.1,0.1,0.1,0.6]`，选择概率最大的`0.6`，即`suis`。\n",
    "\n",
    "以此类推，直到遇到`<\\s>`标签，得到最终的序列`moi suis étudiant`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集束搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的贪心搜索只选择了概率最大的一个，而集束搜索则选择了概率最大的前k个。这个k值也叫做集束宽度（Beam Width）。\n",
    "\n",
    "还是以上面的例子作为说明，k值等于2，则集束搜索的过程如下图："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-blog.csdn.net/20180414113522371?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d1b2xpbmRvbmdnbGQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到第一个输出的概率分布`[0.1,0.1,0.3,0.4,0.1] [0.1,0.1,0.3,0.4,0.1]`，选择概率最大的前两个，`0.3`和`0.4`，即`Je`和`moi`。\n",
    "\n",
    "然后`Je`和`moi`分别作为`Decoder`的输入，得到两个概率分布，然后再选择概率和最大的前两个序列，`0.3+0.8`和`0.4+0.6`，即`Je suis`和`moi suis`。\n",
    "\n",
    "以此类推，最终可以得到两个序列，即`Je suis étudiant`和`moi suis étudiant`，很明显前者的概率和最大，为`2.2`，所以这个序列是最终得到的结果。\n",
    "\n",
    "集束搜索本质上也是贪心的思想，只不过它考虑了更多的候选搜索空间，因此可以得到更多的翻译结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-blog.csdn.net/20181011144011354?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE2MjM0NjEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n",
    "集束搜索可以认为是维特比算法的贪心形式，在维特比所有中由于利用动态规划导致当字典较大时效率低，而集束搜索使用beam size参数来限制在每一步保留下来的可能性词的数量。集束搜索是在测试阶段为了获得更好准确性而采取的一种策略，在训练阶段无需使用。\n",
    "\n",
    "假设字典为[a,b,c]，beam size选择2，则如下图有：\n",
    "\n",
    "1：在生成第1个词的时候，选择概率最大的2个词，那么当前序列就是a或b\n",
    "\n",
    "2：生成第2个词的时候，我们将当前序列a或b，分别与字典中的所有词进行组合，得到新的6个序列aa ab ac ba bb bc,然后从其中选择2个概率最高的，作为当前序列，即ab或bb\n",
    "\n",
    "3：不断重复这个过程，直到遇到结束符为止。最终输出2个概率最高的序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('/home/roger/kaikeba/03_lecture/code')\n",
    "from utils.wv_loader import load_vocab\n",
    "from utils.data_loader import load_dataset\n",
    "from utils.config import *\n",
    "import numpy as np\n",
    "from utils.gpu_utils import config_gpu\n",
    "config_gpu()\n",
    "import tensorflow as tf\n",
    "from seq2seq_tf2.seq2seq_model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, reverse_vocab = load_vocab(vocab_path)\n",
    "batch_size=3\n",
    "vocab_size=len(vocab)\n",
    "params = {}\n",
    "params[\"vocab_size\"] = vocab_size\n",
    "params[\"embed_size\"] = 500\n",
    "params[\"enc_units\"] = 512\n",
    "params[\"attn_units\"] = 512\n",
    "params[\"dec_units\"] = 512\n",
    "params[\"batch_size\"] = batch_size\n",
    "params[\"beam_size\"]=3\n",
    "\n",
    "params['min_dec_steps']=4\n",
    "params['max_dec_steps']=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_Y,test_X = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 31819,\n",
       " 'embed_size': 500,\n",
       " 'enc_units': 512,\n",
       " 'attn_units': 512,\n",
       " 'dec_units': 512,\n",
       " 'batch_size': 32,\n",
       " 'beam_size': 3,\n",
       " 'min_dec_steps': 4,\n",
       " 'max_dec_steps': 50}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Seq2Seq(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seq2seq_tf2.seq2seq_model.Seq2Seq at 0x7ff11c2089b0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 读取训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import checkpoint_dir,checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(Seq2Seq=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis:\n",
    "    \"\"\" Class designed to hold hypothesises throughout the beamSearch decoding \"\"\"\n",
    "    def __init__(self, tokens, log_probs, hidden, attn_dists):\n",
    "        self.tokens = tokens  # list of all the tokens from time 0 to the current time step t\n",
    "        self.log_probs = log_probs  # list of the log probabilities of the tokens of the tokens\n",
    "        self.hidden = hidden  # decoder hidden state after the last token decoding\n",
    "        self.attn_dists = attn_dists  # attention dists of all the tokens\n",
    "        self.abstract = \"\"\n",
    "\n",
    "    def extend(self, token, log_prob, hidden, attn_dist):\n",
    "        \"\"\"Method to extend the current hypothesis by adding the next decoded token and all the informations associated with it\"\"\"\n",
    "        return Hypothesis(tokens=self.tokens + [token],  # we add the decoded token\n",
    "                          log_probs=self.log_probs + [log_prob],  # we add the log prob of the decoded token\n",
    "                          hidden=hidden,  # we update the state\n",
    "                          attn_dists=self.attn_dists + [attn_dist])\n",
    "    @property\n",
    "    def latest_token(self):\n",
    "        return self.tokens[-1]\n",
    "\n",
    "    @property\n",
    "    def tot_log_prob(self):\n",
    "        return sum(self.log_probs)\n",
    "\n",
    "    @property\n",
    "    def avg_log_prob(self):\n",
    "        return self.tot_log_prob / len(self.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化一个对象列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inp=test_X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 200)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output, enc_hidden = model.call_encoder(enc_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 200, 512])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output.sdhape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 512])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = [Hypothesis(tokens=[vocab['<START>']],\n",
    "                   log_probs=[0.0],\n",
    "                   hidden=enc_hidden[0],\n",
    "                   attn_dists=[],\n",
    "                   ) for _ in range(params['batch_size'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab {a c f e p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token [c f p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<START> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x7ff1040cd908>,\n",
       " <__main__.Hypothesis at 0x7ff1040cd860>,\n",
       " <__main__.Hypothesis at 0x7ff1040cd828>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []  # list to hold the top beam_size hypothesises\n",
    "steps = 0  # initial step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取最新tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_tokens = [h.latest_token for h in hyps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31815, 31815, 31815]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 隐藏层状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = [h.hidden for h in hyps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-blog.csdn.net/20180414103300419)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单步运行decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = vocab['<PAD>']\n",
    "nuk_index = vocab['<UNK>']\n",
    "start_index = vocab['<START>']\n",
    "stop_index = vocab['<STOP>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一轮\n",
    "steps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_onestep(enc_output,dec_input,dec_hidden):\n",
    "    # 单个时间步 运行\n",
    "    preds, dec_hidden, context_vector,attention_weights = model.call_decoder_onestep(dec_input,dec_hidden, enc_output)\n",
    "    # 拿到top k个index 和 概率\n",
    "    top_k_probs, top_k_ids = tf.nn.top_k(tf.squeeze(preds), k=params[\"beam_size\"])\n",
    "    # 计算log概率\n",
    "    top_k_log_probs = tf.math.log(top_k_probs)\n",
    "    # 返回需要保存的中间结果和概率\n",
    "    return preds,dec_hidden,context_vector,attention_weights,top_k_log_probs,top_k_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单次搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算第encoder的输出\n",
    "enc_output, enc_hidden = model.call_encoder(enc_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个decoder输入 开始标签\n",
    "dec_input = tf.expand_dims(latest_tokens, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个隐藏层输入\n",
    "dec_hidden = enc_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单步运行\n",
    "preds, dec_hidden, context_vector,attention_weights, top_k_log_probs, top_k_ids = decoder_onestep(enc_output,dec_input,dec_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现阶段全部可能情况\n",
    "all_hyps = []\n",
    "# 原有的可能情况数量\n",
    "num_orig_hyps = 1 if steps == 0 else len(hyps)\n",
    "\n",
    "# 遍历添加所有可能结果\n",
    "for i in range(num_orig_hyps):\n",
    "    h, new_hidden, attn_dist = hyps[i], dec_hidden[i], attention_weights[i]\n",
    "    # 分裂 添加 beam size 种可能性\n",
    "    for j in range(params['beam_size']):\n",
    "        # 构造可能的情况\n",
    "        new_hyp = h.extend(token = top_k_ids[i, j].numpy(),\n",
    "                                       log_prob = top_k_log_probs[i, j],\n",
    "                                       hidden = new_hidden,\n",
    "                                       attn_dist = attn_dist)\n",
    "        # 添加可能情况\n",
    "        all_hyps.append(new_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token c b f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. <start> c  \n",
    "2. <start> b\n",
    "3. <start> f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x7ff10c7eee80>,\n",
       " <__main__.Hypothesis at 0x7ff10c7ee5f8>,\n",
       " <__main__.Hypothesis at 0x7ff10c7eeac8>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置\n",
    "hyps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照概率来排序\n",
    "sorted_hyps = sorted(all_hyps, key=lambda h: h.avg_log_prob, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选top前beam_size句话 top 3\n",
    "for h in sorted_hyps:\n",
    "    if h.latest_token == stop_index:\n",
    "        # 长度符合预期,遇到句尾,添加到结果集\n",
    "        if steps >= params['min_dec_steps']:\n",
    "            results.append(h)\n",
    "    else:\n",
    "        # 未到结束 ,添加到假设集\n",
    "        hyps.append(h)\n",
    "    \n",
    "    # 如果假设句子正好等于beam_size 或者结果集正好等于beam_size 就不在添加\n",
    "    if len(hyps) == params['beam_size'] or len(results) == params['beam_size']:\n",
    "        break\n",
    "steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results) == 0:\n",
    "    results = hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps_sorted = sorted(results, key=lambda h: h.avg_log_prob, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = hyps_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp.abstract = \" \".join([reverse_vocab[index] for index in best_hyp.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> 捡'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyp.abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "[1] https://www.tensorflow.org/tutorials/seq2seq\n",
    "\n",
    "[2] https://blog.csdn.net/guolindonggld/article/details/79938567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beam search 方法整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decode(model,batch,vocab, params):\n",
    "    # 初始化mask\n",
    "    start_index = vocab['<START>']\n",
    "    stop_index = vocab['<STOP>']\n",
    "    \n",
    "    batch_size= params['batch_size']\n",
    "    \n",
    "    # 单步decoder\n",
    "    def decoder_onestep(enc_output,dec_input,dec_hidden):\n",
    "        # 单个时间步 运行\n",
    "        preds, dec_hidden, context_vector,attention_weights = model.call_decoder_onestep(dec_input,dec_hidden, enc_output)\n",
    "        # 拿到top k个index 和 概率\n",
    "        top_k_probs, top_k_ids = tf.nn.top_k(tf.squeeze(preds), k=params[\"beam_size\"])\n",
    "        # 计算log概率\n",
    "        top_k_log_probs = - tf.math.log(top_k_probs)\n",
    "        # 返回需要保存的中间结果和概率\n",
    "        return preds,dec_hidden,context_vector,attention_weights,top_k_log_probs,top_k_ids\n",
    "    \n",
    "    # 计算第encoder的输出\n",
    "    enc_output, enc_hidden = model.call_encoder(batch)\n",
    "    \n",
    "    # 初始化batch size个 假设对象\n",
    "    hyps = [Hypothesis(tokens=[start_index],\n",
    "                   log_probs=[0.0],\n",
    "                   hidden=enc_hidden[0],\n",
    "                   attn_dists=[],\n",
    "                   ) for _ in range(batch_size)]\n",
    "    # 初始化结果集\n",
    "    results = []  # list to hold the top beam_size hypothesises\n",
    "    # 遍历步数\n",
    "    steps = 0  # initial step\n",
    "    \n",
    "    # 第一个隐藏层输入\n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    \n",
    "    # 长度还不够 并且 结果还不够 继续搜索\n",
    "    while steps < params['max_dec_steps'] and len(results) < params['beam_size']:\n",
    "        # 获取最新待使用的token\n",
    "        latest_tokens = [h.latest_token for h in hyps]\n",
    "        # 获取所以隐藏层状态\n",
    "        hiddens = [h.hidden for h in hyps]\n",
    "        # 最新输入\n",
    "        dec_input = tf.expand_dims(latest_tokens, 1)\n",
    "        \n",
    "        # 单步运行decoder 计算需要的值\n",
    "        preds, dec_hidden, context_vector,attention_weights, top_k_log_probs, top_k_ids = decoder_onestep(enc_output,dec_input,dec_hidden)\n",
    "        \n",
    "        # 现阶段全部可能情况\n",
    "        all_hyps = []\n",
    "        # 原有的可能情况数量\n",
    "        num_orig_hyps = 1 if steps == 0 else len(hyps)\n",
    "\n",
    "        # 遍历添加所有可能结果\n",
    "        for i in range(num_orig_hyps):\n",
    "            h, new_hidden, attn_dist = hyps[i], dec_hidden[i], attention_weights[i]\n",
    "            # 分裂 添加 beam size 种可能性\n",
    "            for j in range(params['beam_size']):\n",
    "                if params['batch_size']==1:\n",
    "                    # 构造可能的情况\n",
    "                    new_hyp = h.extend(token = top_k_ids[j].numpy(),\n",
    "                                       log_prob = top_k_log_probs[j],\n",
    "                                       hidden = new_hidden,\n",
    "                                       attn_dist = attn_dist)\n",
    "                else:\n",
    "                    # 构造可能的情况\n",
    "                    new_hyp = h.extend(token = top_k_ids[i, j].numpy(),\n",
    "                                       log_prob = top_k_log_probs[i, j],\n",
    "                                       hidden = new_hidden,\n",
    "                                       attn_dist = attn_dist)\n",
    "                # 添加可能情况\n",
    "                all_hyps.append(new_hyp)\n",
    "        \n",
    "        # 重置\n",
    "        hyps = []\n",
    "        # 按照概率来排序\n",
    "        sorted_hyps = sorted(all_hyps, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "        \n",
    "        # 筛选top前beam_size句话\n",
    "        for h in sorted_hyps:\n",
    "            if h.latest_token == stop_index:\n",
    "                # 长度符合预期,遇到句尾,添加到结果集\n",
    "                if steps >= params['min_dec_steps']:\n",
    "                    results.append(h)\n",
    "            else:\n",
    "                # 未到结束 ,添加到假设集\n",
    "                hyps.append(h)\n",
    "\n",
    "            # 如果假设句子正好等于beam_size 或者结果集正好等于beam_size 就不在添加\n",
    "            if len(hyps) == params['beam_size'] or len(results) == params['beam_size']:\n",
    "                break\n",
    "\n",
    "        steps += 1\n",
    "        \n",
    "    if len(results) == 0:\n",
    "        results = hyps\n",
    "    \n",
    "    hyps_sorted = sorted(results, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "    best_hyp = hyps_sorted[0]\n",
    "    best_hyp.abstract = \" \".join([reverse_vocab[index] for index in best_hyp.tokens])\n",
    "    return best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "model = Seq2Seq(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造数据\n",
    "test_batch=test_X[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 200)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得最好的语句\n",
    "best_hyp=beam_decode(model,test_batch,vocab, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> 左高右 难关 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段 齿合器 某一 第一段'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyp.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture02",
   "language": "python",
   "name": "lecture02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
