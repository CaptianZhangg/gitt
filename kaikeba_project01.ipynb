{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaikeba_project01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STvmv5jIpU25",
        "colab_type": "text"
      },
      "source": [
        "# 安装google云盘必要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh8LsfrJih05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0fda012-f401-4bc7-c55c-f5335c4d098e"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdXf7q7uilIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "7be1a8be-91de-4c51-bf9c-644c6aff9580"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec 22 12:17:24 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nD2lbjJpH05",
        "colab_type": "code",
        "outputId": "2144e3c6-447f-4849-9ba1-a4a9086d5542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF2bbIBaqJb-",
        "colab_type": "text"
      },
      "source": [
        "# 连接google云盘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP0c150VpMPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsZB2X92iRzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c71de2b7-7486-404b-8864-8d0141df2444"
      },
      "source": [
        "!ls drive/kaikeba/project01/code/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 05_seq2seq-Train.ipynb    main.py    README.md\t\t seq2seq_tf2\n",
            "'beam search-Test.ipynb'   notebook   requirements.txt\t utils\n",
            " data\t\t\t   pgn_tf2    result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXYZtSakqB39",
        "colab_type": "text"
      },
      "source": [
        "# 载入代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtof3Upq2zMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install rouge\n",
        "! pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCKJki722vik",
        "colab_type": "code",
        "outputId": "18349bc9-0ce8-4eba-a103-3e8c63ccb499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7a7hgF1qlvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys\n",
        "sys.path.append('drive/kaikeba/project01/code/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAmj6mi4rLfM",
        "colab_type": "text"
      },
      "source": [
        "# 导入训练代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmK9roVHqyS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "d1372288-a1a7-4f81-dce1-ffb89fbd1d58"
      },
      "source": [
        "from seq2seq_tf2.train import train\n",
        "from seq2seq_tf2.test import test\n",
        "from utils.data_loader import build_dataset\n",
        "from utils.config import train_data_path, test_data_path\n",
        "from utils.config import train_x_seg_path, train_y_seg_path, test_x_seg_path, sample_total, batch_size, save_result_dir, \\\n",
        "    vocab_path,checkpoint_dir"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "2019-12-22 12:21:48,767 : DEBUG : Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "2019-12-22 12:21:49,447 : DEBUG : Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.741 seconds.\n",
            "2019-12-22 12:21:49,513 : DEBUG : Loading model cost 0.741 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "2019-12-22 12:21:49,515 : DEBUG : Prefix dict has been built succesfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0PDonsst_3U",
        "colab_type": "text"
      },
      "source": [
        "# 预处理数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IDIvuKUt-3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build_dataset(train_data_path, test_data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqJ51nS4rAo0",
        "colab_type": "text"
      },
      "source": [
        "# 参数设置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMCFY4gNkHFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "9cd54700-7eaf-47f5-e0a2-d1a1eaf291a2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec 22 12:24:07 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXhlkXOdkBxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLyn0Z07Mzv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\"mode\": 'train',\n",
        "      \"max_enc_len\": 200,\n",
        "      \"max_dec_len\": 34,\n",
        "      \"batch_size\":batch_size ,\n",
        "      \"epochs\": 25,\n",
        "      \"vocab_path\": vocab_path,\n",
        "      \"learning_rate\": 0.15,\n",
        "      \"adagrad_init_acc\": 0.1,\n",
        "      \"rand_unif_init_mag\": 0.02,\n",
        "      \"trunc_norm_init_std\": 1e-4,\n",
        "      \"cov_loss_wt\": 1.0,\n",
        "      \"max_grad_norm\": 2.0,\n",
        "      \"vocab_size\": 31820,\n",
        "      \"beam_size\": batch_size,\n",
        "      \"embed_size\": 300,\n",
        "      \"enc_units\": 256,\n",
        "      \"dec_units\": 256,\n",
        "      \"attn_units\": 256,\n",
        "      \"train_seg_x_dir\": train_x_seg_path,\n",
        "      \"train_seg_y_dir\": train_y_seg_path,\n",
        "      \"test_seg_x_dir\": test_x_seg_path,\n",
        "      \"checkpoints_save_steps\": 5,\n",
        "      \"min_dec_steps\": 4,\n",
        "      \"max_train_steps\": sample_total // batch_size,\n",
        "      \"train_pickle_dir\": '/opt/kaikeba/dataset/',\n",
        "      \"save_batch_train_data\": False,\n",
        "      \"load_batch_train_data\": False,\n",
        "      \"test_save_dir\": save_result_dir,\n",
        "      \"pointer_gen\": True,\n",
        "      \"use_coverage\": True,\n",
        "      \"greedy_decode\":False,\n",
        "      \"checkpoint_dir\":checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxzSe--70wIa",
        "colab_type": "text"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5beBeDjk0xES",
        "colab_type": "code",
        "outputId": "4b871ed1-3d10-496e-98e9-c76849e4a52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GPU 700s TPU x s\n",
        "train(params)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n",
            "Building the model ...\n",
            "Epoch 1 Batch 0 Loss 3.9397\n",
            "Epoch 1 Batch 50 Loss 2.5696\n",
            "Epoch 1 Batch 100 Loss 2.9656\n",
            "Epoch 1 Batch 150 Loss 3.0053\n",
            "Epoch 1 Batch 200 Loss 2.7189\n",
            "Epoch 1 Batch 250 Loss 2.7875\n",
            "Epoch 1 Batch 300 Loss 2.9292\n",
            "Epoch 1 Batch 350 Loss 2.9326\n",
            "Epoch 1 Batch 400 Loss 2.7286\n",
            "Epoch 1 Batch 450 Loss 2.9064\n",
            "Epoch 1 Batch 500 Loss 3.0145\n",
            "Epoch 1 Batch 550 Loss 2.9341\n",
            "Epoch 1 Batch 600 Loss 2.9798\n",
            "Epoch 1 Loss 2.9134\n",
            "Time taken for 1 epoch 275.1854691505432 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.8372\n",
            "Epoch 2 Batch 50 Loss 2.8802\n",
            "Epoch 2 Batch 100 Loss 2.5456\n",
            "Epoch 2 Batch 150 Loss 2.6823\n",
            "Epoch 2 Batch 200 Loss 2.1952\n",
            "Epoch 2 Batch 250 Loss 2.3244\n",
            "Epoch 2 Batch 300 Loss 2.2058\n",
            "Epoch 2 Batch 350 Loss 1.9894\n",
            "Epoch 2 Batch 400 Loss 2.1620\n",
            "Epoch 2 Batch 450 Loss 1.9597\n",
            "Epoch 2 Batch 500 Loss 2.0120\n",
            "Epoch 2 Batch 550 Loss 2.3145\n",
            "Epoch 2 Batch 600 Loss 2.1027\n",
            "Saving checkpoint for epoch 2 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-1\n",
            "Epoch 2 Loss 2.2551\n",
            "Time taken for 1 epoch 290.2044105529785 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.8797\n",
            "Epoch 3 Batch 50 Loss 2.0421\n",
            "Epoch 3 Batch 100 Loss 1.7680\n",
            "Epoch 3 Batch 150 Loss 1.7448\n",
            "Epoch 3 Batch 200 Loss 1.8747\n",
            "Epoch 3 Batch 250 Loss 2.0171\n",
            "Epoch 3 Batch 300 Loss 1.8589\n",
            "Epoch 3 Batch 350 Loss 1.7897\n",
            "Epoch 3 Batch 400 Loss 1.8708\n",
            "Epoch 3 Batch 450 Loss 1.8786\n",
            "Epoch 3 Batch 500 Loss 1.6361\n",
            "Epoch 3 Batch 550 Loss 1.8728\n",
            "Epoch 3 Batch 600 Loss 2.0162\n",
            "Epoch 3 Loss 1.8848\n",
            "Time taken for 1 epoch 239.73425722122192 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.6597\n",
            "Epoch 4 Batch 50 Loss 1.8767\n",
            "Epoch 4 Batch 100 Loss 1.6982\n",
            "Epoch 4 Batch 150 Loss 1.7080\n",
            "Epoch 4 Batch 200 Loss 1.6288\n",
            "Epoch 4 Batch 250 Loss 1.8428\n",
            "Epoch 4 Batch 300 Loss 1.7380\n",
            "Epoch 4 Batch 350 Loss 1.8715\n",
            "Epoch 4 Batch 400 Loss 1.7547\n",
            "Epoch 4 Batch 450 Loss 1.6684\n",
            "Epoch 4 Batch 500 Loss 1.8754\n",
            "Epoch 4 Batch 550 Loss 1.5487\n",
            "Epoch 4 Batch 600 Loss 1.8016\n",
            "Saving checkpoint for epoch 4 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-2\n",
            "Epoch 4 Loss 1.7652\n",
            "Time taken for 1 epoch 288.9950966835022 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.5102\n",
            "Epoch 5 Batch 50 Loss 1.7930\n",
            "Epoch 5 Batch 100 Loss 1.6019\n",
            "Epoch 5 Batch 150 Loss 1.6373\n",
            "Epoch 5 Batch 200 Loss 1.6944\n",
            "Epoch 5 Batch 250 Loss 1.8000\n",
            "Epoch 5 Batch 300 Loss 1.6340\n",
            "Epoch 5 Batch 350 Loss 1.7100\n",
            "Epoch 5 Batch 400 Loss 1.6249\n",
            "Epoch 5 Batch 450 Loss 1.5349\n",
            "Epoch 5 Batch 500 Loss 1.6238\n",
            "Epoch 5 Batch 550 Loss 1.6752\n",
            "Epoch 5 Batch 600 Loss 1.5874\n",
            "Epoch 5 Loss 1.6908\n",
            "Time taken for 1 epoch 240.10086750984192 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.6501\n",
            "Epoch 6 Batch 50 Loss 1.5885\n",
            "Epoch 6 Batch 100 Loss 1.8684\n",
            "Epoch 6 Batch 150 Loss 1.6225\n",
            "Epoch 6 Batch 200 Loss 1.6367\n",
            "Epoch 6 Batch 250 Loss 1.8262\n",
            "Epoch 6 Batch 300 Loss 1.6229\n",
            "Epoch 6 Batch 350 Loss 1.7578\n",
            "Epoch 6 Batch 400 Loss 1.5222\n",
            "Epoch 6 Batch 450 Loss 1.5497\n",
            "Epoch 6 Batch 500 Loss 1.5339\n",
            "Epoch 6 Batch 550 Loss 1.6806\n",
            "Epoch 6 Batch 600 Loss 1.6474\n",
            "Saving checkpoint for epoch 6 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-3\n",
            "Epoch 6 Loss 1.6364\n",
            "Time taken for 1 epoch 299.3212893009186 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.5661\n",
            "Epoch 7 Batch 50 Loss 1.5460\n",
            "Epoch 7 Batch 100 Loss 1.6746\n",
            "Epoch 7 Batch 150 Loss 1.5290\n",
            "Epoch 7 Batch 200 Loss 1.6503\n",
            "Epoch 7 Batch 250 Loss 1.6392\n",
            "Epoch 7 Batch 300 Loss 1.5923\n",
            "Epoch 7 Batch 350 Loss 1.7767\n",
            "Epoch 7 Batch 400 Loss 1.6907\n",
            "Epoch 7 Batch 450 Loss 1.5417\n",
            "Epoch 7 Batch 500 Loss 1.6496\n",
            "Epoch 7 Batch 550 Loss 1.4350\n",
            "Epoch 7 Batch 600 Loss 1.6851\n",
            "Epoch 7 Loss 1.5955\n",
            "Time taken for 1 epoch 240.60319924354553 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.4589\n",
            "Epoch 8 Batch 50 Loss 1.6356\n",
            "Epoch 8 Batch 100 Loss 1.5877\n",
            "Epoch 8 Batch 150 Loss 1.5999\n",
            "Epoch 8 Batch 200 Loss 1.6606\n",
            "Epoch 8 Batch 250 Loss 1.4237\n",
            "Epoch 8 Batch 300 Loss 1.6765\n",
            "Epoch 8 Batch 350 Loss 1.4853\n",
            "Epoch 8 Batch 400 Loss 1.5269\n",
            "Epoch 8 Batch 450 Loss 1.5776\n",
            "Epoch 8 Batch 500 Loss 1.6324\n",
            "Epoch 8 Batch 550 Loss 1.5246\n",
            "Epoch 8 Batch 600 Loss 1.3707\n",
            "Saving checkpoint for epoch 8 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-4\n",
            "Epoch 8 Loss 1.5619\n",
            "Time taken for 1 epoch 288.32896733283997 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.5499\n",
            "Epoch 9 Batch 50 Loss 1.6209\n",
            "Epoch 9 Batch 100 Loss 1.4920\n",
            "Epoch 9 Batch 150 Loss 1.6390\n",
            "Epoch 9 Batch 200 Loss 1.4448\n",
            "Epoch 9 Batch 250 Loss 1.4834\n",
            "Epoch 9 Batch 300 Loss 1.4918\n",
            "Epoch 9 Batch 350 Loss 1.6111\n",
            "Epoch 9 Batch 400 Loss 1.7244\n",
            "Epoch 9 Batch 450 Loss 1.5470\n",
            "Epoch 9 Batch 500 Loss 1.5744\n",
            "Epoch 9 Batch 550 Loss 1.4759\n",
            "Epoch 9 Batch 600 Loss 1.5691\n",
            "Epoch 9 Loss 1.5353\n",
            "Time taken for 1 epoch 238.34248185157776 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.4921\n",
            "Epoch 10 Batch 50 Loss 1.5606\n",
            "Epoch 10 Batch 100 Loss 1.5294\n",
            "Epoch 10 Batch 150 Loss 1.7413\n",
            "Epoch 10 Batch 200 Loss 1.4952\n",
            "Epoch 10 Batch 250 Loss 1.5585\n",
            "Epoch 10 Batch 300 Loss 1.6274\n",
            "Epoch 10 Batch 350 Loss 1.4935\n",
            "Epoch 10 Batch 400 Loss 1.4155\n",
            "Epoch 10 Batch 450 Loss 1.3734\n",
            "Epoch 10 Batch 500 Loss 1.4543\n",
            "Epoch 10 Batch 550 Loss 1.5651\n",
            "Epoch 10 Batch 600 Loss 1.4521\n",
            "Saving checkpoint for epoch 10 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-5\n",
            "Epoch 10 Loss 1.5104\n",
            "Time taken for 1 epoch 289.9493646621704 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.4889\n",
            "Epoch 11 Batch 50 Loss 1.5404\n",
            "Epoch 11 Batch 100 Loss 1.5065\n",
            "Epoch 11 Batch 150 Loss 1.3491\n",
            "Epoch 11 Batch 200 Loss 1.5518\n",
            "Epoch 11 Batch 250 Loss 1.5775\n",
            "Epoch 11 Batch 300 Loss 1.4914\n",
            "Epoch 11 Batch 350 Loss 1.4220\n",
            "Epoch 11 Batch 400 Loss 1.5451\n",
            "Epoch 11 Batch 450 Loss 1.5028\n",
            "Epoch 11 Batch 500 Loss 1.5199\n",
            "Epoch 11 Batch 550 Loss 1.5251\n",
            "Epoch 11 Batch 600 Loss 1.5141\n",
            "Epoch 11 Loss 1.4903\n",
            "Time taken for 1 epoch 238.01922845840454 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.3482\n",
            "Epoch 12 Batch 50 Loss 1.4239\n",
            "Epoch 12 Batch 100 Loss 1.3822\n",
            "Epoch 12 Batch 150 Loss 1.3051\n",
            "Epoch 12 Batch 200 Loss 1.4583\n",
            "Epoch 12 Batch 250 Loss 1.5626\n",
            "Epoch 12 Batch 300 Loss 1.4261\n",
            "Epoch 12 Batch 350 Loss 1.5447\n",
            "Epoch 12 Batch 400 Loss 1.3270\n",
            "Epoch 12 Batch 450 Loss 1.4227\n",
            "Epoch 12 Batch 500 Loss 1.3511\n",
            "Epoch 12 Batch 550 Loss 1.5520\n",
            "Epoch 12 Batch 600 Loss 1.3317\n",
            "Saving checkpoint for epoch 12 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-6\n",
            "Epoch 12 Loss 1.4720\n",
            "Time taken for 1 epoch 297.9085714817047 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.5317\n",
            "Epoch 13 Batch 50 Loss 1.3573\n",
            "Epoch 13 Batch 100 Loss 1.3675\n",
            "Epoch 13 Batch 150 Loss 1.4707\n",
            "Epoch 13 Batch 200 Loss 1.4014\n",
            "Epoch 13 Batch 250 Loss 1.4691\n",
            "Epoch 13 Batch 300 Loss 1.5150\n",
            "Epoch 13 Batch 350 Loss 1.4457\n",
            "Epoch 13 Batch 400 Loss 1.3653\n",
            "Epoch 13 Batch 450 Loss 1.3821\n",
            "Epoch 13 Batch 500 Loss 1.3646\n",
            "Epoch 13 Batch 550 Loss 1.5246\n",
            "Epoch 13 Batch 600 Loss 1.3986\n",
            "Epoch 13 Loss 1.4573\n",
            "Time taken for 1 epoch 239.95707511901855 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 1.4038\n",
            "Epoch 14 Batch 50 Loss 1.3620\n",
            "Epoch 14 Batch 100 Loss 1.3936\n",
            "Epoch 14 Batch 150 Loss 1.3959\n",
            "Epoch 14 Batch 200 Loss 1.4173\n",
            "Epoch 14 Batch 250 Loss 1.6055\n",
            "Epoch 14 Batch 300 Loss 1.5757\n",
            "Epoch 14 Batch 350 Loss 1.5339\n",
            "Epoch 14 Batch 400 Loss 1.4910\n",
            "Epoch 14 Batch 450 Loss 1.3500\n",
            "Epoch 14 Batch 500 Loss 1.5859\n",
            "Epoch 14 Batch 550 Loss 1.6090\n",
            "Epoch 14 Batch 600 Loss 1.5113\n",
            "Saving checkpoint for epoch 14 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-7\n",
            "Epoch 14 Loss 1.4448\n",
            "Time taken for 1 epoch 294.65416646003723 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 1.4756\n",
            "Epoch 15 Batch 50 Loss 1.3173\n",
            "Epoch 15 Batch 100 Loss 1.4802\n",
            "Epoch 15 Batch 150 Loss 1.2739\n",
            "Epoch 15 Batch 200 Loss 1.2991\n",
            "Epoch 15 Batch 250 Loss 1.3524\n",
            "Epoch 15 Batch 300 Loss 1.4958\n",
            "Epoch 15 Batch 350 Loss 1.4369\n",
            "Epoch 15 Batch 400 Loss 1.4442\n",
            "Epoch 15 Batch 450 Loss 1.4455\n",
            "Epoch 15 Batch 500 Loss 1.4359\n",
            "Epoch 15 Batch 550 Loss 1.5201\n",
            "Epoch 15 Batch 600 Loss 1.5406\n",
            "Epoch 15 Loss 1.4337\n",
            "Time taken for 1 epoch 239.83612179756165 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 1.4176\n",
            "Epoch 16 Batch 50 Loss 1.4204\n",
            "Epoch 16 Batch 100 Loss 1.3376\n",
            "Epoch 16 Batch 150 Loss 1.2594\n",
            "Epoch 16 Batch 200 Loss 1.3908\n",
            "Epoch 16 Batch 250 Loss 1.3306\n",
            "Epoch 16 Batch 300 Loss 1.5064\n",
            "Epoch 16 Batch 350 Loss 1.4456\n",
            "Epoch 16 Batch 400 Loss 1.5855\n",
            "Epoch 16 Batch 450 Loss 1.3236\n",
            "Epoch 16 Batch 500 Loss 1.4537\n",
            "Epoch 16 Batch 550 Loss 1.4289\n",
            "Epoch 16 Batch 600 Loss 1.6295\n",
            "Saving checkpoint for epoch 16 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-8\n",
            "Epoch 16 Loss 1.4213\n",
            "Time taken for 1 epoch 287.69143438339233 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 1.3253\n",
            "Epoch 17 Batch 50 Loss 1.3459\n",
            "Epoch 17 Batch 100 Loss 1.5265\n",
            "Epoch 17 Batch 150 Loss 1.3971\n",
            "Epoch 17 Batch 200 Loss 1.3735\n",
            "Epoch 17 Batch 250 Loss 1.4096\n",
            "Epoch 17 Batch 300 Loss 1.3939\n",
            "Epoch 17 Batch 350 Loss 1.4395\n",
            "Epoch 17 Batch 400 Loss 1.4090\n",
            "Epoch 17 Batch 450 Loss 1.4557\n",
            "Epoch 17 Batch 500 Loss 1.4007\n",
            "Epoch 17 Batch 550 Loss 1.6564\n",
            "Epoch 17 Batch 600 Loss 1.4066\n",
            "Epoch 17 Loss 1.4112\n",
            "Time taken for 1 epoch 239.30148887634277 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 1.3169\n",
            "Epoch 18 Batch 50 Loss 1.3222\n",
            "Epoch 18 Batch 100 Loss 1.3986\n",
            "Epoch 18 Batch 150 Loss 1.3501\n",
            "Epoch 18 Batch 200 Loss 1.5087\n",
            "Epoch 18 Batch 250 Loss 1.4503\n",
            "Epoch 18 Batch 300 Loss 1.4849\n",
            "Epoch 18 Batch 350 Loss 1.4933\n",
            "Epoch 18 Batch 400 Loss 1.4557\n",
            "Epoch 18 Batch 450 Loss 1.5599\n",
            "Epoch 18 Batch 500 Loss 1.3627\n",
            "Epoch 18 Batch 550 Loss 1.5688\n",
            "Epoch 18 Batch 600 Loss 1.5246\n",
            "Saving checkpoint for epoch 18 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-9\n",
            "Epoch 18 Loss 1.4045\n",
            "Time taken for 1 epoch 286.0936417579651 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 1.3705\n",
            "Epoch 19 Batch 50 Loss 1.3815\n",
            "Epoch 19 Batch 100 Loss 1.3938\n",
            "Epoch 19 Batch 150 Loss 1.4270\n",
            "Epoch 19 Batch 200 Loss 1.4136\n",
            "Epoch 19 Batch 250 Loss 1.2977\n",
            "Epoch 19 Batch 300 Loss 1.3426\n",
            "Epoch 19 Batch 350 Loss 1.3175\n",
            "Epoch 19 Batch 400 Loss 1.3967\n",
            "Epoch 19 Batch 450 Loss 1.5264\n",
            "Epoch 19 Batch 500 Loss 1.4835\n",
            "Epoch 19 Batch 550 Loss 1.5405\n",
            "Epoch 19 Batch 600 Loss 1.5190\n",
            "Epoch 19 Loss 1.3990\n",
            "Time taken for 1 epoch 238.4064929485321 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 1.2979\n",
            "Epoch 20 Batch 50 Loss 1.2814\n",
            "Epoch 20 Batch 100 Loss 1.3698\n",
            "Epoch 20 Batch 150 Loss 1.3965\n",
            "Epoch 20 Batch 200 Loss 1.4967\n",
            "Epoch 20 Batch 250 Loss 1.3631\n",
            "Epoch 20 Batch 300 Loss 1.3998\n",
            "Epoch 20 Batch 350 Loss 1.3387\n",
            "Epoch 20 Batch 400 Loss 1.2669\n",
            "Epoch 20 Batch 450 Loss 1.3935\n",
            "Epoch 20 Batch 500 Loss 1.5010\n",
            "Epoch 20 Batch 550 Loss 1.3581\n",
            "Epoch 20 Batch 600 Loss 1.3255\n",
            "Saving checkpoint for epoch 20 at /content/drive/kaikeba/project01/code/data/checkpoints/training_checkpoints_seq2seq/ckpt-10\n",
            "Epoch 20 Loss 1.3895\n",
            "Time taken for 1 epoch 298.2757122516632 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 1.3992\n",
            "Epoch 21 Batch 50 Loss 1.4205\n",
            "Epoch 21 Batch 100 Loss 1.2983\n",
            "Epoch 21 Batch 150 Loss 1.3809\n",
            "Epoch 21 Batch 200 Loss 1.4050\n",
            "Epoch 21 Batch 250 Loss 1.3501\n",
            "Epoch 21 Batch 300 Loss 1.4083\n",
            "Epoch 21 Batch 350 Loss 1.3679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-af305d14dd86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/kaikeba/project01/code/seq2seq_tf2/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 训练模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/kaikeba/project01/code/seq2seq_tf2/train_helper.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, vocab, params, checkpoint_manager)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK296ljJPzXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(params)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}